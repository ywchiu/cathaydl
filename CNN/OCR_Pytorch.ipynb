{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 載入套件"
      ],
      "metadata": {
        "id": "ZhiZNjXtHbKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from itertools import groupby\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "import torchvision.transforms.functional as TF\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "oezo2-C6Hf2T"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 設定超參數"
      ],
      "metadata": {
        "id": "n-lqTXhQHe10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "num_classes = 11 # 分類的類別數量，包括手寫數字 0 到 9 以及一個空白標籤。\n",
        "blank_label = 10 # 代表空白的標籤，用於序列中不包含手寫數字的位置。\n",
        "image_height = 28\n",
        "gru_hidden_size = 128 # GRU（Gated Recurrent Unit）的隱藏層維度，即記憶體單元的大小。\n",
        "gru_num_layers = 2 # GRU 的層數，用於指定 GRU 模型的深度。\n",
        "cnn_output_height = 4 # 卷積神經網絡（CNN）輸出特徵圖的高度（以像素為單位）。\n",
        "cnn_output_width = 32 # 卷積神經網絡（CNN）輸出特徵圖的寬度（以像素為單位）。\n",
        "digits_per_sequence = 5 # 每個序列中包含的手寫數字數量。\n",
        "number_of_sequences = 10000 # 要生成的手寫數字序列的總數量。\n"
      ],
      "metadata": {
        "id": "aCxeLpQKHf-v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 產生手寫OCR 資料集"
      ],
      "metadata": {
        "id": "uLqBkKHPHmX_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtsoUzCg68d_",
        "outputId": "344de464-7e48-4c92-82f2-7ad9b83e9558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to ./EMNIST/EMNIST/raw/gzip.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 561753746/561753746 [00:05<00:00, 95137264.96it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./EMNIST/EMNIST/raw/gzip.zip to ./EMNIST/EMNIST/raw\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import numpy as np\n",
        "\n",
        "# 創建 EMNIST 資料集物件，專注於手寫數字字符\n",
        "emnist_dataset = datasets.EMNIST('./EMNIST', split=\"digits\", train=True, download=True)\n",
        "\n",
        "# 初始化空列表，用於儲存序列圖像和標籤\n",
        "dataset_sequences = []\n",
        "dataset_labels = []\n",
        "\n",
        "# 迴圈用於生成指定數量的序列\n",
        "for i in range(number_of_sequences):\n",
        "    # 從 EMNIST 資料集中隨機選擇索引\n",
        "    random_indices = np.random.randint(len(emnist_dataset.data), size=(digits_per_sequence,))\n",
        "    random_digits_images = emnist_dataset.data[random_indices]\n",
        "    transformed_random_digits_images = []\n",
        "\n",
        "    # 迴圈對每個隨機選擇的數字圖像進行轉換\n",
        "    for img in random_digits_images:\n",
        "        # 將張量圖像轉換為 PIL 圖像\n",
        "        img = transforms.ToPILImage()(img)\n",
        "        # 將圖像逆時針旋轉 -90 度，並以填充值 0 進行填充\n",
        "        img = TF.rotate(img, -90, fill=0)\n",
        "        # 水平翻轉圖像\n",
        "        img = TF.hflip(img)\n",
        "        # 使用隨機仿射變換（旋轉、平移、縮放）\n",
        "        img = transforms.RandomAffine(degrees=10, translate=(0.2, 0.15), scale=(0.8, 1.1))(img)\n",
        "        # 將轉換後的 PIL 圖像轉換回張量，然後再轉換為 NumPy 數組\n",
        "        img = transforms.ToTensor()(img).numpy()\n",
        "        transformed_random_digits_images.append(img)\n",
        "\n",
        "    # 將轉換後的圖像列表轉換為 NumPy 數組\n",
        "    random_digits_images = np.array(transformed_random_digits_images)\n",
        "    # 獲取隨機選擇的數字圖像的標籤\n",
        "    random_digits_labels = emnist_dataset.targets[random_indices]\n",
        "    # 將數字圖像序列和標籤進行重塑\n",
        "    random_sequence = np.hstack(random_digits_images.reshape(digits_per_sequence, 28, 28))\n",
        "    random_labels = np.hstack(random_digits_labels.reshape(digits_per_sequence, 1))\n",
        "    # 正規化序列圖像的像素值，並將其儲存到資料集列表中\n",
        "    dataset_sequences.append(random_sequence / 255)\n",
        "    dataset_labels.append(random_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 訓練與測試資料集"
      ],
      "metadata": {
        "id": "_C9xw0eUHtn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_data = torch.Tensor(np.array(dataset_sequences))\n",
        "dataset_labels = torch.IntTensor(np.array(dataset_labels))\n",
        "\n",
        "seq_dataset = data_utils.TensorDataset(dataset_data, dataset_labels)\n",
        "train_set, val_set = torch.utils.data.random_split(seq_dataset,\n",
        "                                                   [int(len(seq_dataset) * 0.8), int(len(seq_dataset) * 0.2)])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "ReQ5k2eJHw1E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CRNN\n",
        "\n",
        "![連結文字](https://ycc.idv.tw/media/CV/crnn_structure.png)"
      ],
      "metadata": {
        "id": "YlrchjSmM3en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CRNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CRNN, self).__init__()\n",
        "\n",
        "        # 卷積層1，輸入通道數 1，輸出通道數 32，卷積核大小 (3, 3)\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 3))\n",
        "        self.norm1 = nn.InstanceNorm2d(32)  # 正規化層\n",
        "        # 卷積層2，輸入通道數 32，輸出通道數 32，卷積核大小 (3, 3)，步長 2\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(3, 3), stride=2)\n",
        "        self.norm2 = nn.InstanceNorm2d(32)\n",
        "        # 卷積層3，輸入通道數 32，輸出通道數 64，卷積核大小 (3, 3)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=(3, 3))\n",
        "        self.norm3 = nn.InstanceNorm2d(64)\n",
        "        # 卷積層4，輸入通道數 64，輸出通道數 64，卷積核大小 (3, 3)，步長 2\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=(3, 3), stride=2)\n",
        "        self.norm4 = nn.InstanceNorm2d(64)\n",
        "\n",
        "        # 計算 GRU 輸入尺寸，即卷積輸出的高度 * 64\n",
        "        self.gru_input_size = cnn_output_height * 64\n",
        "\n",
        "        # 雙向 GRU，輸入尺寸、隱藏層維度、層數、batch_first=True\n",
        "        self.gru = nn.GRU(self.gru_input_size, gru_hidden_size, gru_num_layers, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # 全連接層，將 GRU 輸出映射到類別數量\n",
        "        self.fc = nn.Linear(gru_hidden_size * 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # 通過卷積層1，正規化，並應用 leaky ReLU 激活函數\n",
        "        out = self.conv1(x)\n",
        "        out = self.norm1(out)\n",
        "        out = F.leaky_relu(out)\n",
        "\n",
        "        # 通過卷積層2，正規化，並應用 leaky ReLU 激活函數\n",
        "        out = self.conv2(out)\n",
        "        out = self.norm2(out)\n",
        "        out = F.leaky_relu(out)\n",
        "\n",
        "        # 通過卷積層3，正規化，並應用 leaky ReLU 激活函數\n",
        "        out = self.conv3(out)\n",
        "        out = self.norm3(out)\n",
        "        out = F.leaky_relu(out)\n",
        "\n",
        "        # 通過卷積層4，正規化，並應用 leaky ReLU 激活函數\n",
        "        out = self.conv4(out)\n",
        "        out = self.norm4(out)\n",
        "        out = F.leaky_relu(out)\n",
        "\n",
        "        # 重新排列維度以適合 GRU 輸入\n",
        "        out = out.permute(0, 3, 2, 1)\n",
        "        out = out.reshape(batch_size, -1, self.gru_input_size)\n",
        "\n",
        "        # 通過雙向 GRU 層\n",
        "        out, _ = self.gru(out)\n",
        "\n",
        "        # 通過全連接層，並應用對數 softmax 函數\n",
        "        out = torch.stack([F.log_softmax(self.fc(out[i]), dim=-1) for i in range(out.shape[0])])\n",
        "        return out\n",
        "\n",
        "# 創建 CRNN 模型實例\n",
        "model = CRNN()\n",
        "\n",
        "# 設定連接時間序列的CTC損失函數\n",
        "criterion = nn.CTCLoss(blank=blank_label, reduction='mean', zero_infinity=True)\n",
        "\n",
        "# 定義優化器\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "5Mf2fLQe9uKF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 名詞解釋：\n",
        "\n",
        "**- Instance Normalization**\n",
        "\n",
        "Instance Normalization 中，對於每個輸入實例，它會計算出該實例在每個通道上的平均值和標準差，然後對該實例的每個通道進行獨立的正規化，使其均值為0，標準差為1。這樣的操作可以幫助控制梯度的傳播，並提供穩定的輸入分佈，從而促使模型更好地學習\n",
        "\n",
        "**- CTCLoss**\n",
        "\n",
        "CTCLoss 中，有一個特殊的 \"空白\" 標籤，它表示序列中的間隔。模型可以在預測序列中插入多個空白標籤，以適應預測和目標序列之間的長度不匹配。CTCLoss 通過計算不同的對齊方式下的概率和，然後找到最可能的對齊方式，從而計算模型預測和目標之間的差異。\n",
        "\n",
        "![ctcloss](https://ycc.idv.tw/media/CV/ctc_mapping.png)\n",
        "\n",
        "**- Leaky ReLU（Leaky Rectified Linear Unit）**\n",
        "\n",
        "公式定義如下：\n",
        "\n",
        "f(x) =\n",
        "{\n",
        "x, x > 0\n",
        "αx, x ≤ 0\n",
        "}\n",
        "\n",
        "其中 x 是輸入，α 是一個小的正常數（例如0.01），它的主要作用是當 x 小於或等於 0 時，還能讓神經元有一個小的梯度，避免神經元完全不活躍。解決了 ReLU 函數在 x < 0 時梯度消失的問題，這有助於深度神經網絡中的反向傳播和參數更新。"
      ],
      "metadata": {
        "id": "RbdwGI5KK1Um"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C2vXCCcbNjG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 訓練模型"
      ],
      "metadata": {
        "id": "B3CQl6xqMBB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(epochs):\n",
        "\n",
        "    train_correct = 0  # 正確預測\n",
        "    train_total = 0  # 總樣本\n",
        "\n",
        "    for x_train, y_train in train_loader:\n",
        "\n",
        "        batch_size = x_train.shape[0]  # 當前批次大小，即樣本數\n",
        "        x_train = x_train.view(x_train.shape[0], 1, x_train.shape[1], x_train.shape[2])  # 調整輸入的維度\n",
        "\n",
        "        optimizer.zero_grad()  # 清零梯度\n",
        "        y_pred = model(x_train)  # 使用模型進行預測\n",
        "        y_pred = y_pred.permute(1, 0, 2)  # 改變預測張量的維度，原本維度為(批次大小, 序列長度, 類別數量)，改變成(序列長度, 批次大小, 類別數量)\n",
        "        input_lengths = torch.IntTensor(batch_size).fill_(cnn_output_width)  # 填充輸入序列的長度\n",
        "        target_lengths = torch.IntTensor([len(t) for t in y_train])  # 計算每個目標序列的長度\n",
        "\n",
        "        loss = criterion(y_pred, y_train, input_lengths, target_lengths)  # 計算損失\n",
        "        loss.backward()  # 反向傳播計算梯度\n",
        "        optimizer.step()  # 優化器更新參數\n",
        "\n",
        "        _, max_index = torch.max(y_pred, dim=2)  # 取最大值\n",
        "        for i in range(batch_size):\n",
        "            raw_prediction = list(max_index[:, i].detach().cpu().numpy())  # 轉換預測索引為 NumPy 陣列\n",
        "            prediction = torch.IntTensor([c for c, _ in groupby(raw_prediction) if c != blank_label])  # 去除空白標籤\n",
        "            if len(prediction) == len(y_train[i]) and torch.all(prediction.eq(y_train[i])):\n",
        "                # 如果預測和實際目標序列相同，則計數器增加\n",
        "                train_correct += 1\n",
        "            train_total += 1\n",
        "\n",
        "    # 輸出訓練結果\n",
        "    print('TRAINING. Correct: ', train_correct, '/', train_total, '=', train_correct / train_total)\n"
      ],
      "metadata": {
        "id": "EPFlpiLzNzZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 測試模型"
      ],
      "metadata": {
        "id": "axfNbSmqMDWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_test_imgs = 10  # 指定測試集中的圖像數量\n",
        "test_loader = torch.utils.data.DataLoader(val_set, batch_size=number_of_test_imgs, shuffle=True)  # 使用測試集創建數據載入器\n",
        "test_preds = []  # 儲存測試的預測結果\n",
        "\n",
        "# 獲取下一批測試數據\n",
        "(x_test, y_test) = next(iter(test_loader))\n",
        "\n",
        "# 通過模型進行預測\n",
        "y_pred = model(x_test.view(x_test.shape[0], 1, x_test.shape[1], x_test.shape[2]))\n",
        "y_pred = y_pred.permute(1, 0, 2)  # 重新排列預測張量的維度\n",
        "_, max_index = torch.max(y_pred, dim=2)\n",
        "\n",
        "# 對每個測試樣本進行預測結果處理\n",
        "for i in range(x_test.shape[0]):\n",
        "    raw_prediction = list(max_index[:, i].detach().cpu().numpy())  # 將預測的索引轉換為 NumPy 陣列\n",
        "    prediction = torch.IntTensor([c for c, _ in groupby(raw_prediction) if c != blank_label])  # 去除空白標籤\n",
        "    test_preds.append(prediction)  # 儲存預測結果\n",
        "\n",
        "# 顯示測試結果\n",
        "for j in range(len(x_test)):\n",
        "    mpl.rcParams[\"font.size\"] = 8  # 設置字體大小\n",
        "    plt.imshow(x_test[j], cmap='gray')  # 顯示測試圖像\n",
        "    mpl.rcParams[\"font.size\"] = 18  # 恢復字體大小\n",
        "    plt.gcf().text(x=0.1, y=0.1, s=\"Actual: \" + str(y_test[j].numpy()))  # 顯示實際標籤\n",
        "    plt.gcf().text(x=0.1, y=0.2, s=\"Predicted: \" + str(test_preds[j].numpy()))  # 顯示預測標籤\n",
        "    plt.show()  # 顯示圖像及標籤信息\n"
      ],
      "metadata": {
        "id": "jat1OGY0OI6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_wwN4WYxPLfF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}